version: '3.7'
services:
  tube:
    image: "quay.io/cdis/tube:feat_parser"
    command: bash -c "python run_config.py && sleep 50 && python run_import.py"
    networks:
      - devnet
    environment:
      - DICTIONARY_URL=https://s3.amazonaws.com/dictionary-artifacts/ndhdictionary/3.1.12/schema.json
      - ES_URL=elasticsearch
      - ES_INDEX_NAME=etl
      - HADOOP_URL=hdfs://spark:9000
      - HADOOP_HOST=spark
    volumes:
      - ./configs/creds.json:/usr/share/gen3/tube/creds.json
      - ./configs/etlMapping.yaml:/usr/share/gen3/tube/etlMapping.yaml
    depends_on:
      - spark
  spark:
    image: "quay.io/cdis/gen3-spark:feat_init"
    command: bash -c "python run_config.py && hdfs namenode -format && hdfs --daemon start namenode && hdfs --daemon start datanode && yarn --daemon start resourcemanager && yarn --daemon start nodemanager && hdfs dfsadmin -safemode leave &&  hdfs dfs -mkdir /result && while true; do sleep 5; done"
    expose:
      - 22
      - 8030
      - 8031
      - 8032
      - 9000
    networks:
      - devnet
    environment:
      - HADOOP_URL=hdfs://0.0.0.0:9000
      - HADOOP_HOST=0.0.0.0
networks:
  devnet:
